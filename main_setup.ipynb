{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLDT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import itertools\n",
    "import ast\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the environment:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALL THE DEVICES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number_of_cpu_cores</th>\n",
       "      <th>occupied_cores</th>\n",
       "      <th>voltages_frequencies</th>\n",
       "      <th>ISL</th>\n",
       "      <th>capacitance</th>\n",
       "      <th>powerIdle</th>\n",
       "      <th>batteryLevel</th>\n",
       "      <th>errorRate</th>\n",
       "      <th>acceptableTasks</th>\n",
       "      <th>handleSafeTask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iot 0</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[(80000000.0, 4.0), (10000000.0, 1.8), (16000...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[2.4928983413087824e-10, 2.925029147076276e-10...</td>\n",
       "      <td>[0.0009, 0.0009, 0.001, 0.001, 0.001, 0.0009, ...</td>\n",
       "      <td>3.800000e+10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[3, 4, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iot 1</td>\n",
       "      <td>8</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[(10000000.0, 1.8), (40000000.0, 2.7), (20000...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>[2.025958433654792e-10, 2.0241237749775673e-10...</td>\n",
       "      <td>[0.001, 0.001, 0.001, 0.0009, 0.0009, 0.0009, ...</td>\n",
       "      <td>3.700000e+10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iot 2</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[[(80000000.0, 4.0), (20000000.0, 2.3), (40000...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[2.0703522189736892e-10, 2.541045071012014e-10...</td>\n",
       "      <td>[0.0007999999999999999, 0.001, 0.0007999999999...</td>\n",
       "      <td>3.600000e+10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>[3, 4, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iot 3</td>\n",
       "      <td>8</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[(10000000.0, 1.8), (40000000.0, 2.7), (16000...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[2.2325536185704405e-10, 2.0243182779502887e-1...</td>\n",
       "      <td>[0.0009, 0.0009, 0.0009, 0.0007999999999999999...</td>\n",
       "      <td>3.600000e+10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[2, 3, 4, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iot 4</td>\n",
       "      <td>8</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[(40000000.0, 2.7), (80000000.0, 4.0), (20000...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>[2.871170270860548e-10, 2.3479014270568305e-10...</td>\n",
       "      <td>[0.001, 0.001, 0.001, 0.001, 0.000799999999999...</td>\n",
       "      <td>3.600000e+10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>[2, 4, 1, 3]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>mec 46</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[(600000000.0, 0.8), (1000000000.0, 1.0), (15...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[1.6656868473928285e-09, 1.927477267954804e-09...</td>\n",
       "      <td>[0.65, 0.55, 0.75, 0.65, 0.55, 0.75, 0.75, 0.6...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[4, 3, 2, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>mec 47</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[(750000000.0, 0.825), (600000000.0, 0.8), (1...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[1.9774339762666487e-09, 1.7767494069440676e-0...</td>\n",
       "      <td>[0.65, 0.65, 0.65, 0.65, 0.65, 0.55, 0.75, 0.5...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[4, 2, 1, 3]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>mec 48</td>\n",
       "      <td>64</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[(750000000.0, 0.825), (1000000000.0, 1.0), (...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[1.6989649489337003e-09, 1.833482809665926e-09...</td>\n",
       "      <td>[0.75, 0.75, 0.55, 0.65, 0.75, 0.55, 0.75, 0.6...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>[2, 3, 1, 4]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>mec 49</td>\n",
       "      <td>32</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[(750000000.0, 0.825), (600000000.0, 0.8), (1...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[1.6408775978358996e-09, 1.896929720212431e-09...</td>\n",
       "      <td>[0.75, 0.75, 0.55, 0.55, 0.65, 0.75, 0.65, 0.5...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>cloud</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2800000000.0, 3900000000.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>(13.85, 24.28)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  number_of_cpu_cores  \\\n",
       "0     iot 0                   16   \n",
       "1     iot 1                    8   \n",
       "2     iot 2                    4   \n",
       "3     iot 3                    8   \n",
       "4     iot 4                    8   \n",
       "..      ...                  ...   \n",
       "146  mec 46                   16   \n",
       "147  mec 47                   16   \n",
       "148  mec 48                   64   \n",
       "149  mec 49                   32   \n",
       "150   cloud                    1   \n",
       "\n",
       "                                        occupied_cores  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1                             [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                                         [0, 0, 0, 0]   \n",
       "3                             [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4                             [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "..                                                 ...   \n",
       "146   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "147   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "148  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "149  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "150                                                [0]   \n",
       "\n",
       "                                  voltages_frequencies   ISL  \\\n",
       "0    [[(80000000.0, 4.0), (10000000.0, 1.8), (16000...  0.15   \n",
       "1    [[(10000000.0, 1.8), (40000000.0, 2.7), (20000...  0.16   \n",
       "2    [[(80000000.0, 4.0), (20000000.0, 2.3), (40000...  0.10   \n",
       "3    [[(10000000.0, 1.8), (40000000.0, 2.7), (16000...  0.12   \n",
       "4    [[(40000000.0, 2.7), (80000000.0, 4.0), (20000...  0.20   \n",
       "..                                                 ...   ...   \n",
       "146  [[(600000000.0, 0.8), (1000000000.0, 1.0), (15...  0.00   \n",
       "147  [[(750000000.0, 0.825), (600000000.0, 0.8), (1...  0.00   \n",
       "148  [[(750000000.0, 0.825), (1000000000.0, 1.0), (...  0.00   \n",
       "149  [[(750000000.0, 0.825), (600000000.0, 0.8), (1...  0.00   \n",
       "150                       [2800000000.0, 3900000000.0]  0.00   \n",
       "\n",
       "                                           capacitance  \\\n",
       "0    [2.4928983413087824e-10, 2.925029147076276e-10...   \n",
       "1    [2.025958433654792e-10, 2.0241237749775673e-10...   \n",
       "2    [2.0703522189736892e-10, 2.541045071012014e-10...   \n",
       "3    [2.2325536185704405e-10, 2.0243182779502887e-1...   \n",
       "4    [2.871170270860548e-10, 2.3479014270568305e-10...   \n",
       "..                                                 ...   \n",
       "146  [1.6656868473928285e-09, 1.927477267954804e-09...   \n",
       "147  [1.9774339762666487e-09, 1.7767494069440676e-0...   \n",
       "148  [1.6989649489337003e-09, 1.833482809665926e-09...   \n",
       "149  [1.6408775978358996e-09, 1.896929720212431e-09...   \n",
       "150                                     (13.85, 24.28)   \n",
       "\n",
       "                                             powerIdle  batteryLevel  \\\n",
       "0    [0.0009, 0.0009, 0.001, 0.001, 0.001, 0.0009, ...  3.800000e+10   \n",
       "1    [0.001, 0.001, 0.001, 0.0009, 0.0009, 0.0009, ...  3.700000e+10   \n",
       "2    [0.0007999999999999999, 0.001, 0.0007999999999...  3.600000e+10   \n",
       "3    [0.0009, 0.0009, 0.0009, 0.0007999999999999999...  3.600000e+10   \n",
       "4    [0.001, 0.001, 0.001, 0.001, 0.000799999999999...  3.600000e+10   \n",
       "..                                                 ...           ...   \n",
       "146  [0.65, 0.55, 0.75, 0.65, 0.55, 0.75, 0.75, 0.6...  1.000000e+02   \n",
       "147  [0.65, 0.65, 0.65, 0.65, 0.65, 0.55, 0.75, 0.5...  1.000000e+02   \n",
       "148  [0.75, 0.75, 0.55, 0.65, 0.75, 0.55, 0.75, 0.6...  1.000000e+02   \n",
       "149  [0.75, 0.75, 0.55, 0.55, 0.65, 0.75, 0.65, 0.5...  1.000000e+02   \n",
       "150                                                  0  1.000000e+02   \n",
       "\n",
       "     errorRate acceptableTasks  handleSafeTask  \n",
       "0         0.01       [3, 4, 2]               0  \n",
       "1         0.01       [1, 3, 2]               1  \n",
       "2         0.03       [3, 4, 1]               1  \n",
       "3         0.05    [2, 3, 4, 1]               1  \n",
       "4         0.03    [2, 4, 1, 3]               1  \n",
       "..         ...             ...             ...  \n",
       "146       0.08    [4, 3, 2, 1]               0  \n",
       "147       0.09    [4, 2, 1, 3]               1  \n",
       "148       0.06    [2, 3, 1, 4]               1  \n",
       "149       0.09       [2, 3, 4]               1  \n",
       "150       0.10    [1, 2, 3, 4]               0  \n",
       "\n",
       "[151 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "devices = pd.read_csv(\"./resources/devices.csv\")\n",
    "devices[\"voltages_frequencies\"] = devices[\"voltages_frequencies\"].apply(lambda x: ast.literal_eval(x))\n",
    "devices[\"capacitance\"] = devices[\"capacitance\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "devices[\"occupied_cores\"] = devices[\"occupied_cores\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "devices[\"powerIdle\"] = devices[\"powerIdle\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "devices[\"acceptableTasks\"] = devices[\"acceptableTasks\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "devices = devices.drop([\"Unnamed: 0\"],axis=1)\n",
    "devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _ALL THE TASKS_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tasks():\n",
    "    tasks = pd.read_csv('./resources/tasks.csv')\n",
    "    tasks = tasks.sample(frac=1)\n",
    "    tasks = tasks.set_index(\"id\")\n",
    "    tasks_copy = tasks.copy()\n",
    "    tasks_copy = tasks_copy.drop([\"job\",\"dependency\",\"mobility\",\"status\"],axis=1)\n",
    "    taskList = tasks_copy.index.tolist()\n",
    "    return taskList, tasks_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : DDT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Initializing The tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDT(nn.Module):\n",
    "    def __init__(self, num_input, num_output, depth, max_depth):\n",
    "        super(DDT, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        if depth != max_depth:\n",
    "            # self.weights = nn.Parameter(torch.zeros(num_input))\n",
    "            self.weights = nn.Parameter(torch.empty(\n",
    "                num_input).normal_(mean=0, std=0.1))\n",
    "            self.bias = nn.Parameter(torch.zeros(1))\n",
    "        if depth == max_depth:\n",
    "            self.prob_dist = nn.Parameter(torch.zeros(num_output))\n",
    "\n",
    "        if depth < max_depth:\n",
    "            self.left = DDT(num_input, num_output, depth + 1, max_depth)\n",
    "            self.right = DDT(num_input, num_output, depth + 1, max_depth)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.depth == self.max_depth:\n",
    "            return self.prob_dist\n",
    "        val = torch.sigmoid(torch.matmul(x, self.weights.t()) + self.bias)\n",
    "        a = np.random.uniform(0, 1)\n",
    "        if a < 0.1:\n",
    "            val = 1 - val\n",
    "        if val >= 0.5:\n",
    "\n",
    "            return val * self.right(x)\n",
    "        else:\n",
    "\n",
    "            return (1 - val) * self.left(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: RL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_execution_time(device, task, core, dvfs):\n",
    "    if device['id'] == \"cloud\":\n",
    "        return task[\"computationalLoad\"] / device[\"voltages_frequencies\"][0]\n",
    "    else:\n",
    "        return task[\"computationalLoad\"] / device[\"voltages_frequencies\"][core][dvfs][0]\n",
    "\n",
    "\n",
    "def calc_power_consumption(device, task, core, dvfs):\n",
    "    if device['id'] == \"cloud\":\n",
    "        return 13.85 \n",
    "    return (\n",
    "        device[\"capacitance\"][core]\n",
    "        * (device[\"voltages_frequencies\"][core][dvfs][1] ** 2)\n",
    "        * device[\"voltages_frequencies\"][core][dvfs][0]\n",
    "    )\n",
    "def calc_energy(device, task, core, dvfs):\n",
    "    return calc_execution_time(device, task, core, dvfs) * calc_power_consumption(device, task, core, dvfs)\n",
    "\n",
    "\n",
    "def calc_total(device, task, core, dvfs):\n",
    "    timeTransMec = 0\n",
    "    timeTransCC = 0\n",
    "    exeTime = 0\n",
    "    e = 0\n",
    "\n",
    "    transferRate5g =1e9\n",
    "    latency5g=5e-3\n",
    "    transferRateFiber =1e10\n",
    "    latencyFiber=1e-3\n",
    "\n",
    "    timeDownMec = task[\"returnDataSize\"] / transferRate5g\n",
    "    timeDownMec += latency5g\n",
    "    timeUpMec = task[\"dataEntrySize\"] / transferRate5g\n",
    "    timeUpMec += latency5g\n",
    "\n",
    "    alpha = 52e-5\n",
    "    beta = 3.86412\n",
    "    powerMec = alpha * 1e9 / 1e6 + beta\n",
    "\n",
    "    timeDownCC = task[\"returnDataSize\"] / transferRateFiber\n",
    "    timeDownCC += latencyFiber\n",
    "    timeUpCC = task[\"dataEntrySize\"] / transferRateFiber\n",
    "    timeUpCC += latencyFiber\n",
    "\n",
    "    powerCC = 3.65 \n",
    "\n",
    "\n",
    "    if device[\"id\"].startswith(\"mec\"):\n",
    "        timeTransMec =  timeUpMec +  timeDownMec \n",
    "        energyTransMec = powerMec *  timeTransMec\n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime = exeTime + timeTransMec \n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy =  e + energyTransMec\n",
    "\n",
    "    elif device['id'].startswith(\"cloud\"):\n",
    "        timeTransMec =  timeUpMec +  timeDownMec \n",
    "        energyTransMec = powerMec * timeTransMec\n",
    "        \n",
    "        timeTransCC = timeUpCC+timeDownCC\n",
    "        energyTransCC =  powerCC * timeTransCC\n",
    "        \n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime =  exeTime + timeTransMec +timeTransCC\n",
    "\n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy = e + energyTransMec + energyTransCC\n",
    "\n",
    "    elif device['id'].startswith(\"iot\"):\n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime = exeTime\n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy = e\n",
    "\n",
    "    return totalTime , totalEnergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPunish(rSetup):\n",
    "    match rSetup:\n",
    "        case \"00\":\n",
    "            p = 10\n",
    "        case \"01\":\n",
    "            p = 10\n",
    "        case \"02\":\n",
    "            p = 100\n",
    "        case \"03\":\n",
    "            p = 100\n",
    "        case \"04\":\n",
    "            p = 20\n",
    "        case \"05\":\n",
    "            p = 20\n",
    "        case \"06\":\n",
    "            p = 15\n",
    "        case \"07\":\n",
    "            p = 15\n",
    "        case \"08\":\n",
    "            p = 10\n",
    "        case \"09\":\n",
    "            p = 10\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfSuitable(state, device, punish):\n",
    "    punishment = 0\n",
    "    safeFail = 0\n",
    "    taskFail = 0\n",
    "    if  state['safe'] and not device[\"handleSafeTask\"]:\n",
    "        punishment += 1\n",
    "        safeFail += 1\n",
    "        \n",
    "    if state['kind'] not in device[\"acceptableTasks\"]:\n",
    "        punishment += 1\n",
    "        taskFail += 1\n",
    "    # return taskFail, safeFail\n",
    "    return (punishment if punishment > 0 else 0, taskFail, safeFail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSetup(t, e, setup, alpha=1, beta=1):\n",
    "    match setup:\n",
    "        case \"00\":\n",
    "            reward = (alpha * e + beta * t)\n",
    "        case \"01\":\n",
    "            reward = -1 / (alpha * e + beta * t)\n",
    "        case \"02\":\n",
    "            reward = -np.exp(alpha * e) - np.exp(beta * t)\n",
    "        case \"03\":\n",
    "            reward = -np.exp(alpha * e + beta * t)\n",
    "        case \"04\":\n",
    "            reward = np.exp(-1 * (alpha * e + beta * t))\n",
    "        case \"05\":\n",
    "            reward = np.log(alpha * e + beta * t)\n",
    "        case \"06\": \n",
    "            reward = -((alpha * e + beta * t) ** 2)\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.learning_mode = 0\n",
    "        self.rSetup = \"01\"\n",
    "        self.punish = 0\n",
    "        self.alpha = 1\n",
    "        self.beta = 1\n",
    "        self.last_epoch_t = 0\n",
    "        self.last_epoch_l = 0\n",
    "        self.last_epoch_e = 0\n",
    "        self.taskList = []\n",
    "        self.tasks_copy = None\n",
    "        self.totalSafeFail = 0\n",
    "        self.totalTaskFail = 0\n",
    "        self.totalReward = 0\n",
    "        self.feature_size = 5\n",
    "        self.num_actions = len(devices)\n",
    "        self.max_depth = 3\n",
    "        self.agent = DDT(self.feature_size, self.num_actions,\n",
    "                         depth=0, max_depth=self.max_depth)\n",
    "        self.optimizer = optim.Adam(self.agent.parameters(), lr=0.005)\n",
    "        self.avg_time_history = []\n",
    "        self.avg_energy_history = []\n",
    "        self.avg_fail_history = []\n",
    "        self.avg_safe_fail_history = []\n",
    "        self.avg_task_fail_history = []\n",
    "     \n",
    "    def execute_action(self, state, action):\n",
    "        self.taskList.pop(0)\n",
    "        device = devices.iloc[action]        \n",
    "\n",
    "        punishment, taskFail, safeFail = checkIfSuitable(state, device, self.punish)\n",
    "\n",
    "        # taskFail, safeFail = checkIfSuitable(state, device)\n",
    "        punishment *= self.punish\n",
    "        \n",
    "\n",
    "        if safeFail:\n",
    "            self.totalSafeFail += 1\n",
    "        if taskFail:\n",
    "            self.totalTaskFail += 1\n",
    "\n",
    "\n",
    "        if not (punishment):\n",
    "            for coreIndex in range(len(device[\"occupied_cores\"])):\n",
    "                if device[\"occupied_cores\"][coreIndex] == 0:\n",
    "                    total_t, total_e  = calc_total(device, state, coreIndex,np.random.randint(0,3))\n",
    "                    reward = getSetup(total_t, total_e, self.rSetup, alpha=self.alpha, beta=self.beta)\n",
    "                    # reward = -1 / (total_t + total_e)\n",
    "                    # print(f\"device {device['id']} ////// time {total_t}  ////// energy {total_e} \")\n",
    "                    self.totalReward += reward\n",
    "                    return (self.tasks_copy.loc[self.taskList[0]], reward, total_t, total_e)\n",
    "        self.totalFail += 1\n",
    "        return (self.tasks_copy.loc[self.taskList[0]], punishment, 0, 0)\n",
    "\n",
    "\n",
    "    def train(self, num_epoch, num_episodes):\n",
    "\n",
    "        total_avg_t = 0\n",
    "        total_avg_e = 0\n",
    "        total_avg_r = 0\n",
    "        total_avg_l = 0\n",
    "        \n",
    "        self.safeFailHistory = []\n",
    "        self.taskFailHistory = []\n",
    "        self.lossHistory = []\n",
    "\n",
    "        half_num_epoch = (num_epoch - 1) // 2\n",
    "        \n",
    "        for i in range(num_epoch):\n",
    "            \n",
    "\n",
    "\n",
    "            total_loss = 0\n",
    "            self.totalFail = 0\n",
    "            self.totalTaskFail = 0\n",
    "            self.totalSafeFail = 0\n",
    "            self.totalReward = 0\n",
    "            total_loss = 0\n",
    "            total_reward = 0\n",
    "            totalTime = 0\n",
    "            totalEnergy = 0\n",
    "\n",
    "\n",
    "            \n",
    "            for j in range(num_episodes):\n",
    "                state = self.tasks_copy.loc[self.taskList[0]]\n",
    "                x = torch.tensor(np.array(state.values, dtype=np.float32)).unsqueeze(0)\n",
    "                \n",
    "                output = self.agent(x)\n",
    "                action_probabilities = torch.softmax(output, dim=0)\n",
    "                action_index = torch.multinomial(action_probabilities, 1).item()\n",
    "                # action_index = torch.argmax(action_probabilities).item()\n",
    "\n",
    "                next_state, reward, t, e = self.execute_action(state, action_index)\n",
    "                loss = (output[action_index] * reward)\n",
    "\n",
    "                if self.learning_mode == 0:\n",
    "                    #single reward:\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                total_reward += reward\n",
    "                total_loss += loss\n",
    "                \n",
    "                totalTime += t\n",
    "                totalEnergy += e\n",
    "                \n",
    "            if self.learning_mode == 1:\n",
    "                    #total\n",
    "                    self.optimizer.zero_grad()\n",
    "                    total_loss.backward()\n",
    "                    self.optimizer.step()   \n",
    "            \n",
    "            avg_time = totalTime / num_episodes\n",
    "            avg_energy = totalEnergy / num_episodes\n",
    "            # avg_reward = total_reward / num_episodes\n",
    "            avg_reward = self.totalReward / num_episodes\n",
    "            avg_loss = total_loss/num_episodes\n",
    "\n",
    "            if self.learning_mode == 2:\n",
    "                #avg\n",
    "                self.optimizer.zero_grad()\n",
    "                avg_loss = total_loss/num_episodes\n",
    "                avg_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "            self.lossHistory.append(avg_loss)\n",
    "            self.avg_time_history.append(avg_time)\n",
    "            self.avg_energy_history.append(avg_energy)\n",
    "            self.avg_fail_history.append(self.totalFail)\n",
    "            self.avg_safe_fail_history.append(self.totalSafeFail)\n",
    "            self.avg_task_fail_history.append(self.totalTaskFail)\n",
    "\n",
    "\n",
    "            total_avg_t += avg_time\n",
    "            total_avg_e += avg_energy\n",
    "            total_avg_l += avg_loss\n",
    "            total_avg_r += avg_reward\n",
    "            \n",
    "\n",
    "            \n",
    "            if i % 1 == 0:\n",
    "                # print(f\"Epoch {i+1} // avg cc time: {avg_cc} // avg mec: {avg_mec} // avg og time: {avg_og} total fail: {env.totalFail} // Average Loss: {avg_loss}// \")\n",
    "                # print(f\"Epoch {i+1} // avg time: {avg_time} // avg added Time: {avg_added_time} // avg og time: {avg_og} total fail: {env.totalFail} // Average Loss: {avg_loss}// \")\n",
    "                # print(f\"Epoch {i+1}  // safe/task fail: {self.totalSafeFail}/{self.totalTaskFail} // Average Loss: {avg_loss:.2f} // Total Reward: {self.totalReward:.2f} // Average Reward: {avg_reward:.2f} // Avg time: {avg_time:.2f} // Avg energy: {avg_energy:.2f}\")\n",
    "                pass\n",
    "            \n",
    "\n",
    "            \n",
    "            if i == num_epoch - 1:\n",
    "\n",
    "                self.last_epoch_t = avg_time\n",
    "                self.last_epoch_l = avg_loss\n",
    "                self.last_epoch_e = avg_energy\n",
    "                \n",
    "            \n",
    "                \n",
    "            #     print(f\"safe/task fail: {env.totalSafeFail}/{env.totalTaskFail} // Average Loss: {avg_loss:.2f} // Total Reward: {env.totalReward:.2f} // Average Reward: {avg_reward:.2f} // Avg time: {avg_time:.2f} // Avg energy: {avg_energy:.2f}\")\n",
    "\n",
    "                # env.totalFail = 0\n",
    "            self.taskFailHistory.append(self.totalTaskFail)\n",
    "            self.safeFailHistory.append(self.totalSafeFail)\n",
    "            self.totalSafeFail = 0\n",
    "            self.totalTaskFail = 0\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        avg_avg_t = total_avg_t / num_epoch\n",
    "        avg_avg_l = total_avg_l / num_epoch\n",
    "        avg_avg_r = total_avg_r / num_epoch\n",
    "        avg_avg_e = total_avg_e / num_epoch\n",
    "\n",
    "        # Initializing variables to default values\n",
    "        last_safe_index = 0  \n",
    "        last_task_index = 0  \n",
    "\n",
    "        safe_fail_indices = [i for i, x in enumerate(self.safeFailHistory) if x != 0]\n",
    "        if safe_fail_indices:\n",
    "            last_safe_index = safe_fail_indices[-1] + 1\n",
    "        \n",
    "        task_fail_indices = [i for i, x in enumerate(self.taskFailHistory) if x != 0]\n",
    "        if task_fail_indices:\n",
    "            last_task_index = task_fail_indices[-1] + 1\n",
    "        \n",
    "        task_fail_percent = len(task_fail_indices) / num_epoch\n",
    "        safe_fail_percent = len(safe_fail_indices) / num_epoch\n",
    "        is_loss_min = 1 if self.last_epoch_l < min(self.lossHistory) else 0\n",
    "\n",
    "        first_10_avg_time = np.mean(self.avg_time_history[:10])\n",
    "        first_10_avg_energy = np.mean(self.avg_energy_history[:10])\n",
    "        first_10_avg_safe_fail = np.mean(self.avg_safe_fail_history[:10])\n",
    "        first_10_avg_task_fail = np.mean(self.avg_task_fail_history[:10])\n",
    "        first_10_total_fail = np.sum(self.taskFailHistory[:10]) + np.sum(self.safeFailHistory[:10])\n",
    "        first_10_fail_arr = [first_10_total_fail, first_10_avg_task_fail, first_10_avg_safe_fail]\n",
    "\n",
    "        mid_10_avg_time = np.mean(self.avg_time_history[half_num_epoch:half_num_epoch + 10])\n",
    "        mid_10_avg_energy = np.mean(self.avg_energy_history[half_num_epoch:half_num_epoch + 10])\n",
    "        mid_10_avg_safe_fail = np.mean(self.avg_safe_fail_history[half_num_epoch:half_num_epoch + 10])\n",
    "        mid_10_avg_task_fail = np.mean(self.avg_task_fail_history[half_num_epoch:half_num_epoch + 10])\n",
    "        mid_10_total_fail = np.sum(self.taskFailHistory[half_num_epoch:half_num_epoch + 10]) + np.sum(self.safeFailHistory[half_num_epoch:half_num_epoch + 10])\n",
    "        mid_10_fail_arr = [mid_10_total_fail, mid_10_avg_task_fail, mid_10_avg_safe_fail]\n",
    "\n",
    "        last_10_avg_time = np.mean(self.avg_time_history[-10:])\n",
    "        last_10_avg_energy = np.mean(self.avg_energy_history[-10:])\n",
    "        last_10_avg_safe_fail = np.mean(self.avg_safe_fail_history[-10:])\n",
    "        last_10_avg_task_fail = np.mean(self.avg_task_fail_history[-10:])\n",
    "        last_10_total_fail = np.sum(self.taskFailHistory[-10:]) + np.sum(self.safeFailHistory[-10:])\n",
    "        last_10_fail_arr = [last_10_total_fail, last_10_avg_task_fail, last_10_avg_safe_fail]\n",
    "\n",
    "        new_epoch_data = {\n",
    "            \"Setup\": [self.rSetup],\n",
    "            \"Learning Mode\": [self.learning_mode],\n",
    "            \"Punishment\": [self.punish],\n",
    "            \"Alpha\": [self.alpha],\n",
    "            \"Beta\": [self.beta],\n",
    "            \"Average Loss\": [avg_avg_l.detach().numpy() if isinstance(avg_avg_l, torch.Tensor) else avg_avg_l],\n",
    "            \"Last Epoch Loss\": [self.last_epoch_l.detach().numpy() if isinstance(self.last_epoch_l, torch.Tensor) else self.last_epoch_l],\n",
    "            \"is Loss min\": [is_loss_min.detach().numpy() if isinstance(is_loss_min, torch.Tensor) else is_loss_min],\n",
    "            \"Task Converge\": [last_task_index.detach().numpy() if isinstance(last_task_index, torch.Tensor) else last_task_index],\n",
    "            \"Task Fail Percentage\": [task_fail_percent.detach().numpy() if isinstance(task_fail_percent, torch.Tensor) else task_fail_percent],\n",
    "            \"Safe Converge\": [last_safe_index.detach().numpy() if isinstance(last_safe_index, torch.Tensor) else last_safe_index],\n",
    "            \"Safe Fail Percentage\": [safe_fail_percent.detach().numpy() if isinstance(safe_fail_percent, torch.Tensor) else safe_fail_percent],\n",
    "            \"Average Time\": [avg_avg_t.detach().numpy() if isinstance(avg_avg_t, torch.Tensor) else avg_avg_t],\n",
    "            \"Last Epoch Time\": [self.last_epoch_t.detach().numpy() if isinstance(self.last_epoch_t, torch.Tensor) else self.last_epoch_t],\n",
    "            \"Average Energy\": [avg_avg_e.detach().numpy() if isinstance(avg_avg_e, torch.Tensor) else avg_avg_e],\n",
    "            \"Last Epoch Energy\": [self.last_epoch_e.detach().numpy() if isinstance(self.last_epoch_e, torch.Tensor) else self.last_epoch_e],\n",
    "            \"Average Reward\": [avg_avg_r.detach().numpy() if isinstance(avg_avg_r, torch.Tensor) else avg_avg_r],\n",
    "            \"Total Reward\": [total_reward.detach().numpy() if isinstance(total_reward, torch.Tensor) else total_reward],\n",
    "\n",
    "            \"First 10 Avg Time\": [first_10_avg_time.detach().numpy() if isinstance(first_10_avg_time, torch.Tensor) else first_10_avg_time],\n",
    "            \"Mid 10 Avg Time\": [mid_10_avg_time.detach().numpy() if isinstance(mid_10_avg_time, torch.Tensor) else mid_10_avg_time],\n",
    "            \"Last 10 Avg Time\": [last_10_avg_time.detach().numpy() if isinstance(last_10_avg_time, torch.Tensor) else last_10_avg_time],\n",
    "            \"First 10 Avg Energy\": [first_10_avg_energy.detach().numpy() if isinstance(first_10_avg_energy, torch.Tensor) else first_10_avg_energy],\n",
    "            \"Mid 10 Avg Energy\": [mid_10_avg_energy.detach().numpy() if isinstance(mid_10_avg_energy, torch.Tensor) else mid_10_avg_energy],\n",
    "            \"Last 10 Avg Energy\": [last_10_avg_energy.detach().numpy() if isinstance(last_10_avg_energy, torch.Tensor) else last_10_avg_energy],\n",
    "            \"First 10 (total, task, safe) Fail\": [first_10_fail_arr],\n",
    "            \"Mid 10 (total, task, safe) Fail\": [mid_10_fail_arr],\n",
    "            \"Last 10 (total, task, safe) Fail\": [last_10_fail_arr]\n",
    "        }   \n",
    "\n",
    "\n",
    "\n",
    "        # print(f'Overall Average Time across all epochs: {avg_avg_t}')\n",
    "        # print(f'Overall Average e across all epochs: {avg_avg_e:.2f}')\n",
    "        # print(f'Overall Average l across all epochs: {avg_avg_l:.2f}')\n",
    "        # print(f'Overall Average r across all epochs: {avg_avg_r:.2f}') \n",
    "\n",
    "        df = pd.read_csv(dataFile)\n",
    "\n",
    "        # Convert the new data into a DataFrame and concatenate it\n",
    "        new_df = pd.DataFrame(new_epoch_data)\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "        # Save the updated DataFrame back to CSV\n",
    "        df.to_csv(dataFile, index=False)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot([l.detach().numpy() if isinstance(l, torch.Tensor) else l for l in self.lossHistory], label='Average Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f\"Training Loss History with setup {self.rSetup}, punish: {self.punish}, mode: {self.learning_mode}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        # print(f'Overall Average Time across all epochs: {avg_avg_t}')\n",
    "        # print(f'Overall Average e across all epochs: {avg_avg_e:.2f}')\n",
    "        # print(f'Overall Average l across all epochs: {avg_avg_l:.2f}')\n",
    "        # print(f'Overall Average r across all epochs: {avg_avg_r:.2f}')\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# env.totalAddedAvg += avg_cc\n",
    "\n",
    "\n",
    "# env = Environment()\n",
    "# tree = env.agent\n",
    "# env.train(1001, 10)\n",
    "\n",
    "# print('///////////////////')\n",
    "\n",
    "# for name, param in env.agent.named_parameters():\n",
    "#     if \"prob_dist\" or \"bias\" not in name:\n",
    "#         # print(name,param)\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m                         tree \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39magent\n\u001b[1;32m     18\u001b[0m                         env\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m10001\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m, in \u001b[0;36mtrain_test\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     15\u001b[0m env\u001b[38;5;241m.\u001b[39mtasks_copy \u001b[38;5;241m=\u001b[39m tasks_copy\n\u001b[1;32m     17\u001b[0m tree \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39magent\n\u001b[0;32m---> 18\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 102\u001b[0m, in \u001b[0;36mEnvironment.train\u001b[0;34m(self, num_epoch, num_episodes)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    101\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m    105\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/ROV/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ROV/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/envs/ROV/lib/python3.10/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/ROV/lib/python3.10/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ROV/lib/python3.10/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def train_test(n):\n",
    "    rpSetup_list = {\"00\": [10, 100, 1000], \"01\": [100, 1000, 10000], \"02\": [20, 200, 2000], \"03\": [15, 150, 1500], \"04\": [10, 100, 1000], \"05\": [20, 200, 2000], \"06\": [2, 20, 200] }\n",
    "    learningModes = [0, 1, 2]\n",
    "\n",
    "    for i in range(n):\n",
    "        for reward, punish_list in rpSetup_list.items():\n",
    "            for punish in punish_list:\n",
    "                    for mode in learningModes:\n",
    "                        taskList, tasks_copy = read_tasks()\n",
    "                        env = Environment()\n",
    "                        env.learning_mode = mode\n",
    "                        env.rSetup = reward\n",
    "                        env.punish = punish\n",
    "                        env.taskList = taskList\n",
    "                        env.tasks_copy = tasks_copy\n",
    "                        \n",
    "                        tree = env.agent\n",
    "                        env.train(10001, 10)\n",
    "\n",
    "train_test(1)   \n",
    "print(\"completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the column headers as a list\n",
    "# headers = [\n",
    "#     \"Setup\",\"Learning Mode\", \"Punishment\", \"Alpha\", \"Beta\",\"Average Loss\", \"Last Epoch Loss\", \"is Loss min\", \"Task Converge\", \"Task Fail Percentage\", \"Safe Converge\", \"Safe Fail Percentage\", \"Average Time\",\"Last Epoch Time\",\n",
    "#     \"Average Energy\", \"Last Epoch Energy\", \"Average Reward\", \"Total Reward\", \"First 10 Avg Time\", \"Mid 10 Avg Time\",\"Last 10 Avg Time\",\"First 10 Avg Energy\", \"Mid 10 Avg Energy\",\"Last 10 Avg Energy\", \"First 10 (total, task, safe) Fail\", \"Mid 10 (total, task, safe) Fail\", \"Last 10 (total, task, safe) Fail\"\n",
    "# ]\n",
    "# # Create an empty DataFrame with these headers\n",
    "# df = pd.DataFrame(columns=headers)\n",
    "\n",
    "# # Specify the filename\n",
    "# filename = dataFile\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# df.to_csv(filename, index=False)\n",
    "\n",
    "# print(f\"CSV file '{filename}' created successfully with headers only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file sorted by 'setup'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(dataFile)\n",
    "\n",
    "# Sort the DataFrame by 'setup' column\n",
    "df = df.sort_values(by='Setup')\n",
    "\n",
    "# Save the sorted DataFrame back to the CSV\n",
    "df.to_csv(dataFile, index=False)\n",
    "\n",
    "print(\"CSV file sorted by 'setup'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012000000000000001\n",
      "0.6400000000000001\n",
      "0.1315236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_test():\n",
    "    rpSetup_list = {\"01\": [1, 10, 100, 1000]}\n",
    "    alpha_list = [1]\n",
    "    beta_list = [1, 2, 5, 10, 20]\n",
    "    \n",
    "    for reward, punishments in rpSetup_list.items():\n",
    "        for punish, alpha, beta in itertools.product(punishments, alpha_list, beta_list):   \n",
    "            # if alpha == beta and alpha != 1:\n",
    "            #     continue\n",
    "            \n",
    "            taskList, tasks_copy = read_tasks()\n",
    "            env = Environment()\n",
    "            env.rSetup = reward\n",
    "            env.alpha = alpha\n",
    "            env.beta = beta\n",
    "            env.punish = punish\n",
    "            env.taskList = taskList\n",
    "            env.tasks_copy = tasks_copy\n",
    "            \n",
    "            tree = env.agent\n",
    "            env.train(10001, 10)\n",
    "\n",
    "train_test()   \n",
    "print(\"completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
