{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLDT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_IOT_devices = 10\n",
    "\n",
    "voltages_frequencies_IOT = [\n",
    "    (10e6  , 1.8),\n",
    "    (20e6  , 2.3),\n",
    "    (40e6  , 2.7),\n",
    "    (80e6  , 4.0),\n",
    "    (160e6 , 5.0),\n",
    "]\n",
    "\n",
    "num_MEC_devices = 5\n",
    "\n",
    "voltages_frequencies_MEC = [\n",
    "    (1500e6 ,  1.2),\n",
    "    (1000e6 ,  1.0),\n",
    "    (750e6, 0.825),\n",
    "    (600e6, 0.8),\n",
    "]\n",
    "\n",
    "task_kinds = [1,2,3,4]\n",
    "\n",
    "min_num_nodes_dag = 4\n",
    "max_num_nodes_dag = 20\n",
    "max_num_parents_dag = 5\n",
    "num_dag_generations = 10000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the environment:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALL THE DEVICES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "devices = pd.read_csv(\"devices.csv\")\n",
    "devices[\"voltages_frequencies\"] = devices[\"voltages_frequencies\"].apply(lambda x: ast.literal_eval(x))\n",
    "devices[\"capacitance\"] = devices[\"capacitance\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "devices[\"occupied_cores\"] = devices[\"occupied_cores\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "devices[\"powerIdle\"] = devices[\"powerIdle\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "devices[\"acceptableTasks\"] = devices[\"acceptableTasks\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "devices = devices.drop([\"Unnamed: 0\"],axis=1)\n",
    "# devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _ALL THE TASKS_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_dag(num_nodes):\n",
    "    dag = nx.DiGraph()\n",
    "\n",
    "    nodes = [f\"t{i+1}\" for i in range(num_nodes)]\n",
    "    dag.add_nodes_from(nodes)\n",
    "\n",
    "    available_parents = {node: list(nodes[:i]) for i, node in enumerate(nodes)}\n",
    "\n",
    "    for i in range(2, num_nodes + 1):\n",
    "\n",
    "        num_parents = min(\n",
    "            random.randint(1, min(i, max_num_parents_dag)), len(\n",
    "                available_parents[f\"t{i}\"])\n",
    "        )\n",
    "\n",
    "        # select parents\n",
    "        parent_nodes = random.sample(available_parents[f\"t{i}\"], num_parents)\n",
    "        # add parents\n",
    "        dag.add_edges_from((parent_node, f\"t{i}\")\n",
    "                           for parent_node in parent_nodes)\n",
    "\n",
    "        # update available parents\n",
    "        available_parents[f\"t{i}\"] = list(nodes[:i])\n",
    "\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task():\n",
    "    tasks_data = []\n",
    "\n",
    "    start_node_number = 1\n",
    "    for run in range(num_dag_generations):\n",
    "\n",
    "        num_nodes = random.randint(min_num_nodes_dag, max_num_nodes_dag)\n",
    "\n",
    "        random_dag = generate_random_dag(num_nodes)\n",
    "\n",
    "        mapping = {\n",
    "            f\"t{i}\": f\"t{i + start_node_number - 1}\" for i in range(1, num_nodes + 1)\n",
    "        }\n",
    "\n",
    "        random_dag = nx.relabel_nodes(random_dag, mapping)\n",
    "        for node in random_dag.nodes:\n",
    "            parents = list(random_dag.predecessors(node))\n",
    "            task_info = {\n",
    "                \"id\": node,\n",
    "                \"job\": run,\n",
    "                \"dependency\": parents,\n",
    "                \"mobility\": np.random.randint(1, 10),\n",
    "                \"kind\": np.random.choice(task_kinds),\n",
    "                \"safe\": np.random.choice([0, 1], p=[0.95, 0.05]),\n",
    "                \"computationalLoad\": int(np.random.uniform(1, 11)*1e6),\n",
    "                \"dataEntrySize\":int(np.random.uniform(1, 11)*1e6),\n",
    "                \"returnDataSize\":int(np.random.uniform(1, 11)*1e6),\n",
    "                \"status\": \"READY\",\n",
    "            }\n",
    "            tasks_data.append(task_info)\n",
    "        start_node_number += num_nodes\n",
    "\n",
    "    np.random.shuffle(tasks_data)\n",
    "    tasks = pd.DataFrame(tasks_data)\n",
    "    tasks = tasks.set_index(\"id\")\n",
    "    tasks_copy = tasks.copy()\n",
    "    tasks_copy = tasks_copy.drop([\"job\",\"dependency\",\"mobility\",\"status\"],axis=1)\n",
    "    taskList = tasks_copy.index.tolist()\n",
    "    return taskList, tasks_copy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : DDT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Initializing The tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDT(nn.Module):\n",
    "    def __init__(self, num_input, num_output, depth, max_depth):\n",
    "        super(DDT, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        if depth != max_depth:\n",
    "            # self.weights = nn.Parameter(torch.zeros(num_input))\n",
    "            self.weights = nn.Parameter(torch.empty(\n",
    "                num_input).normal_(mean=0, std=0.1))\n",
    "            self.bias = nn.Parameter(torch.zeros(1))\n",
    "        if depth == max_depth:\n",
    "            self.prob_dist = nn.Parameter(torch.zeros(num_output))\n",
    "\n",
    "        if depth < max_depth:\n",
    "            self.left = DDT(num_input, num_output, depth + 1, max_depth)\n",
    "            self.right = DDT(num_input, num_output, depth + 1, max_depth)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.depth == self.max_depth:\n",
    "            return self.prob_dist\n",
    "        val = torch.sigmoid(torch.matmul(x, self.weights.t()) + self.bias)\n",
    "        a = np.random.uniform(0, 1)\n",
    "        if a < 0.1:\n",
    "            val = 1 - val\n",
    "        if val >= 0.5:\n",
    "\n",
    "            return val * self.right(x)\n",
    "        else:\n",
    "\n",
    "            return (1 - val) * self.left(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: RL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_execution_time(device, task, core, dvfs):\n",
    "    if device['id'] == \"cloud\":\n",
    "        return task[\"computationalLoad\"] / device[\"voltages_frequencies\"][0]\n",
    "    else:\n",
    "        return task[\"computationalLoad\"] / device[\"voltages_frequencies\"][core][dvfs][0]\n",
    "\n",
    "\n",
    "def calc_power_consumption(device, task, core, dvfs):\n",
    "    if device['id'] == \"cloud\":\n",
    "        return 13.85 * calc_execution_time(device, task, core, dvfs)\n",
    "    return (\n",
    "        device[\"capacitance\"][core]\n",
    "        * (device[\"voltages_frequencies\"][core][dvfs][1] ** 2)\n",
    "        * device[\"voltages_frequencies\"][core][dvfs][0]\n",
    "    )\n",
    "def calc_energy(device, task, core, dvfs):\n",
    "    return calc_execution_time(device, task, core, dvfs) * calc_power_consumption(device, task, core, dvfs)\n",
    "\n",
    "\n",
    "def calc_total(device, task, core, dvfs):\n",
    "    timeTransMec = 0\n",
    "    timeTransCC = 0\n",
    "    exeTime = 0\n",
    "    e = 0\n",
    "\n",
    "    transferRate5g =1e9\n",
    "    latency5g=5e-3\n",
    "    transferRateFiber =1e10\n",
    "    latencyFiber=1e-3\n",
    "\n",
    "    timeDownMec = task[\"returnDataSize\"] / transferRate5g\n",
    "    timeDownMec += latency5g\n",
    "    timeUpMec = task[\"dataEntrySize\"] / transferRate5g\n",
    "    timeUpMec += latency5g\n",
    "\n",
    "    alpha = 52e-5\n",
    "    beta = 3.86412\n",
    "    powerMec = alpha * 1e9 / 1e6 + beta\n",
    "\n",
    "    timeDownCC = task[\"returnDataSize\"] / transferRateFiber\n",
    "    timeDownCC += latencyFiber\n",
    "    timeUpCC = task[\"dataEntrySize\"] / transferRateFiber\n",
    "    timeUpCC += latencyFiber\n",
    "\n",
    "    powerCC = 3.65 \n",
    "\n",
    "\n",
    "    if device[\"id\"].startswith(\"mec\"):\n",
    "        timeTransMec =  timeUpMec +  timeDownMec \n",
    "        energyTransMec = powerMec *  timeTransMec\n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime = exeTime + timeTransMec \n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy =  e + energyTransMec\n",
    "\n",
    "    elif device['id'].startswith(\"cloud\"):\n",
    "        timeTransMec =  timeUpMec +  timeDownMec \n",
    "        energyTransMec = powerMec * timeTransMec\n",
    "        \n",
    "        timeTransCC = timeUpCC+timeDownCC\n",
    "        energyTransCC =  powerCC * timeTransCC\n",
    "        \n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime =  exeTime + timeTransMec +timeTransCC\n",
    "\n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy =  + energyTransMec + energyTransCC\n",
    "\n",
    "    elif device['id'].startswith(\"iot\"):\n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime = exeTime\n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy = e\n",
    "\n",
    "    return totalTime , totalEnergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPunish(rSetup):\n",
    "    match rSetup:\n",
    "        case \"00\":\n",
    "            p = 10\n",
    "        case \"01\":\n",
    "            p = 10\n",
    "        case \"02\":\n",
    "            p = 100\n",
    "        case \"03\":\n",
    "            p = 100\n",
    "        case \"04\":\n",
    "            p = 20\n",
    "        case \"05\":\n",
    "            p = 20\n",
    "        case \"06\":\n",
    "            p = 15\n",
    "        case \"07\":\n",
    "            p = 15\n",
    "        case \"08\":\n",
    "            p = 10\n",
    "        case \"09\":\n",
    "            p = 10\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfSuitable(state, device, punish):\n",
    "    punishment = 0\n",
    "    safeFail = 0\n",
    "    taskFail = 0\n",
    "    if  state['safe'] and not device[\"handleSafeTask\"]:\n",
    "        punishment += 1\n",
    "        safeFail += 1\n",
    "        \n",
    "    if state['kind'] not in device[\"acceptableTasks\"]:\n",
    "        punishment += 1\n",
    "        taskFail += 1\n",
    "    # return taskFail, safeFail\n",
    "    return (punishment if punishment > 0 else 0, taskFail, safeFail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSetup(t, e, setup, alpha=1, beta=1):\n",
    "    match setup:\n",
    "        case \"00\":\n",
    "            reward = -1 * (e + t)\n",
    "        case \"01\":\n",
    "            reward = -1 * (alpha * e + beta * t)\n",
    "        case \"02\":\n",
    "            reward = -1 / (e + t)\n",
    "        case \"03\":\n",
    "            reward = -1 / (alpha * e + beta * t)\n",
    "        case \"04\":\n",
    "            reward = -np.exp(e) - np.exp(t)\n",
    "        case \"05\":\n",
    "            reward = -np.exp(alpha * e) - np.exp(beta * t)\n",
    "        case \"06\":\n",
    "            reward = -np.exp(t + e)\n",
    "        case \"07\":\n",
    "            reward = -np.exp(alpha * t + beta * e)\n",
    "        case \"08\":\n",
    "            reward = np.exp(-t - e)\n",
    "        case \"09\":\n",
    "            reward = np.exp(-1 * (alpha * t + beta * e))\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.rSetup = \"01\"\n",
    "        self.punish = 0\n",
    "        self.alpha = 1\n",
    "        self.beta = 1\n",
    "        self.last_epoch_t = 0\n",
    "        self.last_epoch_l = 0\n",
    "        self.last_epoch_e = 0\n",
    "        self.taskList = []\n",
    "        self.tasks_copy = None\n",
    "        self.totalSafeFail = 0\n",
    "        self.totalTaskFail = 0\n",
    "        self.totalReward = 0\n",
    "        self.feature_size = 5\n",
    "        self.num_actions = len(devices)\n",
    "        self.max_depth = 3\n",
    "        self.agent = DDT(self.feature_size, self.num_actions,\n",
    "                         depth=0, max_depth=self.max_depth)\n",
    "        self.optimizer = optim.Adam(self.agent.parameters(), lr=0.005)\n",
    "        self.avg_time_history = []\n",
    "        self.avg_energy_history = []\n",
    "        self.avg_fail_history = []\n",
    "        self.avg_safe_fail_history = []\n",
    "        self.avg_task_fail_history = []\n",
    "     \n",
    "    def execute_action(self, state, action):\n",
    "        self.taskList.pop(0)\n",
    "        device = devices.iloc[action]        \n",
    "\n",
    "        punishment, taskFail, safeFail = checkIfSuitable(state, device, self.punish)\n",
    "        # taskFail, safeFail = checkIfSuitable(state, device)\n",
    "        self.punish *= punishment\n",
    "\n",
    "        if safeFail:\n",
    "            self.totalSafeFail += 1\n",
    "        if taskFail:\n",
    "            self.totalTaskFail += 1\n",
    "\n",
    "\n",
    "        if not (self.punish):\n",
    "            for coreIndex in range(len(device[\"occupied_cores\"])):\n",
    "                if device[\"occupied_cores\"][coreIndex] == 0:\n",
    "                    total_t, total_e  = calc_total(device, state, coreIndex,np.random.randint(0,3))\n",
    "                    reward = getSetup(total_t, total_e, self.rSetup, alpha=self.alpha, beta=self.beta)\n",
    "                    # reward = -1 / (total_t + total_e)\n",
    "                    # print(f\"device {device['id']} ////// time {total_t}  ////// energy {total_e} \")\n",
    "                    self.totalReward += reward\n",
    "                    return (self.tasks_copy.loc[self.taskList[0]], reward, total_t, total_e)\n",
    "        self.totalFail += 1\n",
    "        return (self.tasks_copy.loc[self.taskList[0]], self.punish, 0, 0)\n",
    "\n",
    "\n",
    "    def train(self, num_epoch, num_episodes):\n",
    "\n",
    "        total_avg_t = 0\n",
    "        total_avg_e = 0\n",
    "        total_avg_r = 0\n",
    "        total_avg_l = 0\n",
    "        \n",
    "        self.safeFailHistory = []\n",
    "        self.taskFailHistory = []\n",
    "        self.lossHistory = []\n",
    "        \n",
    "        for i in range(num_epoch):\n",
    "            \n",
    "\n",
    "\n",
    "            total_loss = 0\n",
    "            self.totalFail = 0\n",
    "            self.totalTaskFail = 0\n",
    "            self.totalSafeFail = 0\n",
    "            self.totalReward = 0\n",
    "            total_loss = 0\n",
    "            total_reward = 0\n",
    "            totalTime = 0\n",
    "            totalEnergy = 0\n",
    "\n",
    "\n",
    "            \n",
    "            for j in range(num_episodes):\n",
    "                state = self.tasks_copy.loc[self.taskList[0]]\n",
    "                x = torch.tensor(np.array(state.values, dtype=np.float32)).unsqueeze(0)\n",
    "                \n",
    "                output = self.agent(x)\n",
    "                action_probabilities = torch.softmax(output, dim=0)\n",
    "                action_index = torch.multinomial(action_probabilities, 1).item()\n",
    "                # action_index = torch.argmax(action_probabilities).item()\n",
    "\n",
    "                next_state, reward, t, e = self.execute_action(state, action_index)\n",
    "                loss = (output[action_index] * reward)\n",
    "\n",
    "                total_reward += reward\n",
    "                total_loss += loss\n",
    "                \n",
    "                totalTime += t\n",
    "                totalEnergy += e\n",
    "                \n",
    "                \n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            avg_loss = total_loss/num_episodes\n",
    "            self.lossHistory.append(avg_loss)\n",
    "            avg_time = totalTime / num_episodes\n",
    "            avg_energy = totalEnergy / num_episodes\n",
    "            \n",
    "            # avg_reward = total_reward / num_episodes\n",
    "            avg_reward = self.totalReward / num_episodes\n",
    "            avg_loss = total_loss/num_episodes\n",
    "\n",
    "            self.avg_time_history.append(avg_time)\n",
    "            self.avg_energy_history.append(avg_energy)\n",
    "            self.avg_fail_history.append(self.totalFail)\n",
    "            self.avg_safe_fail_history.append(self.totalSafeFail)\n",
    "            self.avg_task_fail_history.append(self.totalTaskFail)\n",
    "\n",
    "\n",
    "            total_avg_t += avg_time\n",
    "            total_avg_e += avg_energy\n",
    "            total_avg_l += avg_loss\n",
    "            total_avg_r += avg_reward\n",
    "            \n",
    "\n",
    "            avg_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if i % 1 == 0:\n",
    "                # print(f\"Epoch {i+1} // avg cc time: {avg_cc} // avg mec: {avg_mec} // avg og time: {avg_og} total fail: {env.totalFail} // Average Loss: {avg_loss}// \")\n",
    "                # print(f\"Epoch {i+1} // avg time: {avg_time} // avg added Time: {avg_added_time} // avg og time: {avg_og} total fail: {env.totalFail} // Average Loss: {avg_loss}// \")\n",
    "                # print(f\"Epoch {i+1}  // safe/task fail: {self.totalSafeFail}/{self.totalTaskFail} // Average Loss: {avg_loss:.2f} // Total Reward: {self.totalReward:.2f} // Average Reward: {avg_reward:.2f} // Avg time: {avg_time:.2f} // Avg energy: {avg_energy:.2f}\")\n",
    "                pass\n",
    "            \n",
    "            if i == 10000:\n",
    "\n",
    "                self.last_epoch_t = avg_time\n",
    "                self.last_epoch_l = avg_loss\n",
    "                self.last_epoch_e = avg_energy\n",
    "                \n",
    "            \n",
    "                \n",
    "            #     print(f\"safe/task fail: {env.totalSafeFail}/{env.totalTaskFail} // Average Loss: {avg_loss:.2f} // Total Reward: {env.totalReward:.2f} // Average Reward: {avg_reward:.2f} // Avg time: {avg_time:.2f} // Avg energy: {avg_energy:.2f}\")\n",
    "\n",
    "                # env.totalFail = 0\n",
    "            self.taskFailHistory.append(self.totalTaskFail)\n",
    "            self.safeFailHistory.append(self.totalSafeFail)\n",
    "            self.totalSafeFail = 0\n",
    "            self.totalTaskFail = 0\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        avg_avg_t = total_avg_t / num_epoch\n",
    "        avg_avg_l = total_avg_l / num_epoch\n",
    "        avg_avg_r = total_avg_r / num_epoch\n",
    "        avg_avg_e = total_avg_e / num_epoch\n",
    "\n",
    "        \n",
    "\n",
    "        safe_fail_indices = [i for i, x in enumerate(self.safeFailHistory) if x != 0]\n",
    "        if safe_fail_indices:\n",
    "            last_safe_index = safe_fail_indices[-1] + 1\n",
    "        \n",
    "        task_fail_indices = [i for i, x in enumerate(self.taskFailHistory) if x != 0]\n",
    "        if task_fail_indices:\n",
    "            last_task_index = task_fail_indices[-1] + 1\n",
    "        \n",
    "        task_fail_percent = len(task_fail_indices) / num_epoch\n",
    "        safe_fail_percent = len(safe_fail_indices) / num_epoch\n",
    "        is_loss_min = 1 if self.last_epoch_l < min(self.lossHistory) else 0\n",
    "\n",
    "        first_10_avg_time = np.mean(self.avg_time_history[:10])\n",
    "        first_10_avg_energy = np.mean(self.avg_energy_history[:10])\n",
    "        first_10_avg_fail = np.mean(self.avg_fail_history[:10])\n",
    "        first_10_avg_safe_fail = np.mean(self.avg_safe_fail_history[:10])\n",
    "        first_10_avg_task_fail = np.mean(self.avg_task_fail_history[:10])\n",
    "\n",
    "        last_10_avg_time = np.mean(self.avg_time_history[-10:])\n",
    "        last_10_avg_energy = np.mean(self.avg_energy_history[-10:])\n",
    "        last_10_avg_fail = np.mean(self.avg_fail_history[-10:])\n",
    "        last_10_avg_safe_fail = np.mean(self.avg_safe_fail_history[-10:])\n",
    "        last_10_avg_task_fail = np.mean(self.avg_task_fail_history[-10:])\n",
    "\n",
    "        \n",
    "        new_epoch_data = {\n",
    "            \"Setup\": [self.rSetup],\n",
    "            \"Punishment\": [self.punish],\n",
    "            \"Alpha\": [self.alpha],\n",
    "            \"Beta\": [self.beta],\n",
    "            \"Average Loss\": [avg_avg_l.detach().numpy() if isinstance(avg_avg_l, torch.Tensor) else avg_avg_l],\n",
    "            \"Last Epoch Loss\": [self.last_epoch_l.detach().numpy() if isinstance(self.last_epoch_l, torch.Tensor) else self.last_epoch_l],\n",
    "            \"is Loss min\": [is_loss_min.detach().numpy() if isinstance(is_loss_min, torch.Tensor) else is_loss_min],\n",
    "            \"Task Converge\": [last_task_index.detach().numpy() if isinstance(last_task_index, torch.Tensor) else last_task_index],\n",
    "            \"Task Fail Percentage\": [task_fail_percent.detach().numpy() if isinstance(task_fail_percent, torch.Tensor) else task_fail_percent],\n",
    "            \"Safe Converge\": [last_safe_index.detach().numpy() if isinstance(last_safe_index, torch.Tensor) else last_safe_index],\n",
    "            \"Safe Fail Percentage\": [safe_fail_percent.detach().numpy() if isinstance(safe_fail_percent, torch.Tensor) else safe_fail_percent],\n",
    "            \"Average Time\": [avg_avg_t.detach().numpy() if isinstance(avg_avg_t, torch.Tensor) else avg_avg_t],\n",
    "            \"Last Epoch Time\": [self.last_epoch_t.detach().numpy() if isinstance(self.last_epoch_t, torch.Tensor) else self.last_epoch_t],\n",
    "            \"Average Energy\": [avg_avg_e.detach().numpy() if isinstance(avg_avg_e, torch.Tensor) else avg_avg_e],\n",
    "            \"Last Epoch Energy\": [self.last_epoch_e.detach().numpy() if isinstance(self.last_epoch_e, torch.Tensor) else self.last_epoch_e],\n",
    "            \"Average Reward\": [avg_avg_r.detach().numpy() if isinstance(avg_avg_r, torch.Tensor) else avg_avg_r],\n",
    "            \"Total Reward\": [total_reward.detach().numpy() if isinstance(total_reward, torch.Tensor) else total_reward],\n",
    "\n",
    "            \"First 10 Avg Time\": [first_10_avg_time.detach().numpy() if isinstance(first_10_avg_time, torch.Tensor) else first_10_avg_time],\n",
    "            \"Last 10 Avg Time\": [last_10_avg_time.detach().numpy() if isinstance(last_10_avg_time, torch.Tensor) else last_10_avg_time],\n",
    "            \"First 10 Avg Energy\": [first_10_avg_energy.detach().numpy() if isinstance(first_10_avg_energy, torch.Tensor) else first_10_avg_energy],\n",
    "            \"Last 10 Avg Energy\": [last_10_avg_energy.detach().numpy() if isinstance(last_10_avg_energy, torch.Tensor) else last_10_avg_energy],\n",
    "            \"First 10 Avg Safe Fail\": [first_10_avg_safe_fail.detach().numpy() if isinstance(first_10_avg_safe_fail, torch.Tensor) else first_10_avg_safe_fail],\n",
    "            \"Last 10 Avg Safe Fail\": [last_10_avg_safe_fail.detach().numpy() if isinstance(last_10_avg_safe_fail, torch.Tensor) else last_10_avg_safe_fail],\n",
    "            \"First 10 Avg Task Fail\": [first_10_avg_task_fail.detach().numpy() if isinstance(first_10_avg_task_fail, torch.Tensor) else first_10_avg_task_fail],\n",
    "            \"Last 10 Avg Task Fail\": [last_10_avg_task_fail.detach().numpy() if isinstance(last_10_avg_task_fail, torch.Tensor) else last_10_avg_task_fail]\n",
    "        }   \n",
    "\n",
    "        df = pd.read_csv(\"data2.csv\")\n",
    "\n",
    "        # Convert the new data into a DataFrame and concatenate it\n",
    "        new_df = pd.DataFrame(new_epoch_data)\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "        # Save the updated DataFrame back to CSV\n",
    "        df.to_csv(\"data2.csv\", index=False)\n",
    "\n",
    "\n",
    "        # print(f'Overall Average Time across all epochs: {avg_avg_t}')\n",
    "        # print(f'Overall Average e across all epochs: {avg_avg_e:.2f}')\n",
    "        # print(f'Overall Average l across all epochs: {avg_avg_l:.2f}')\n",
    "        # print(f'Overall Average r across all epochs: {avg_avg_r:.2f}')\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# env.totalAddedAvg += avg_cc\n",
    "\n",
    "\n",
    "# env = Environment()\n",
    "# tree = env.agent\n",
    "# env.train(1001, 10)\n",
    "\n",
    "# print('///////////////////')\n",
    "\n",
    "# for name, param in env.agent.named_parameters():\n",
    "#     if \"prob_dist\" or \"bias\" not in name:\n",
    "#         # print(name,param)\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/7fw_p5qd057b2drkmtmpn2l80000gn/T/ipykernel_68515/2886625192.py:217: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_test():\n",
    "    rpSetup_list = {\"01\": [1, 10, 100, 1000], \"03\": [10, 100, 1000, 10000], \"05\": [2, 20, 200, 2000], \"07\": [1.5, 15, 150, 1500], \"09\": [1, 10, 100, 1000]}\n",
    "    alpha_list = [1, 2, 5, 10, 20]\n",
    "    beta_list = [1, 2, 5, 10, 20]\n",
    "    \n",
    "    for reward, punishments in rpSetup_list.items():\n",
    "        for punish, alpha, beta in itertools.product(punishments, alpha_list, beta_list):   \n",
    "            if alpha == beta and alpha != 1:\n",
    "                continue\n",
    "            \n",
    "            taskList, tasks_copy = generate_task()\n",
    "            env = Environment()\n",
    "            env.rSetup = reward\n",
    "            env.alpha = alpha\n",
    "            env.beta = beta\n",
    "            env.punish = punish\n",
    "            env.taskList = taskList\n",
    "            env.tasks_copy = tasks_copy\n",
    "            \n",
    "            tree = env.agent\n",
    "            env.train(10001, 10)\n",
    "\n",
    "train_test()   \n",
    "print(\"completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'data2.csv' created successfully with headers only.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Define the column headers as a list\n",
    "# headers = [\n",
    "#     \"Setup\", \"Punishment\", \"Alpha\", \"Beta\",\"Average Loss\", \"Last Epoch Loss\", \"is Loss min\", \"Task Converge\", \"Task Fail Percentage\", \"Safe Converge\", \"Safe Fail Percentage\", \"Average Time\",\"Last Epoch Time\",\n",
    "#     \"Average Energy\", \"Last Epoch Energy\", \"Average Reward\", \"Total Reward\", \"First 10 Avg Time\", \"Last 10 Avg Time\",\"First 10 Avg Energy\", \"Last 10 Avg Energy\",\"First 10 Avg Safe Fail\", \"Last 10 Avg Safe Fail\",\"First 10 Avg Task Fail\", \"Last 10 Avg Task Fail\"\n",
    "# ]\n",
    "# # Create an empty DataFrame with these headers\n",
    "# df = pd.DataFrame(columns=headers)\n",
    "\n",
    "# # Specify the filename\n",
    "# filename = \"data2.csv\"\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# df.to_csv(filename, index=False)\n",
    "\n",
    "# print(f\"CSV file '{filename}' created successfully with headers only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Sort the DataFrame by 'setup' column\n",
    "df = df.sort_values(by='Setup')\n",
    "\n",
    "# Save the sorted DataFrame back to the CSV\n",
    "df.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "print(\"CSV file sorted by 'setup'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
