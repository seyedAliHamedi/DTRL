{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLDT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the environment:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Devices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Gloabl variables_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "source": [
    "num_IOT_devices = 10\n",
    "\n",
    "voltages_frequencies_IOT = [\n",
    "    (10e6  , 1.8),\n",
    "    (20e6  , 2.3),\n",
    "    (40e6  , 2.7),\n",
    "    (80e6  , 4.0),\n",
    "    (160e6 , 5.0),\n",
    "]\n",
    "\n",
    "num_MEC_devices = 5\n",
    "\n",
    "voltages_frequencies_MEC = [\n",
    "    (1500e6 ,  1.2),\n",
    "    (1000e6 ,  1.0),\n",
    "    (750e6, 0.825),\n",
    "    (600e6, 0.8),\n",
    "]\n",
    "\n",
    "task_kinds = [1,2,3,4]\n",
    "\n",
    "min_num_nodes_dag = 4\n",
    "max_num_nodes_dag = 20\n",
    "max_num_parents_dag = 5\n",
    "num_dag_generations = 10000\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _IOT_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "source": [
    "devices_data_IOT = []\n",
    "for i in range(num_IOT_devices):\n",
    "    cpu_cores = np.random.choice([4, 8, 16])\n",
    "    device_info = {\n",
    "        \"id\": f\"iot {i}\",\n",
    "        \"number_of_cpu_cores\": cpu_cores,\n",
    "        \"occupied_cores\": [0 for _ in range(cpu_cores)],\n",
    "        \"voltages_frequencies\": [\n",
    "            [\n",
    "                voltages_frequencies_IOT[i]\n",
    "                for i in np.random.choice(5, size=3, replace=False)\n",
    "            ]\n",
    "            for core in range(cpu_cores)\n",
    "        ],\n",
    "        \"ISL\": np.random.randint(10, 21) / 100,\n",
    "        \"capacitance\": [np.random.uniform(2, 3) * 1e-10 for _ in range(cpu_cores)],\n",
    "        \"powerIdle\": [\n",
    "            np.random.choice([800, 900,1000]) * 1e-6 for _ in range(cpu_cores)\n",
    "        ],\n",
    "        \"batteryLevel\": np.random.randint(36, 41) * 1e9,\n",
    "        \"errorRate\": np.random.randint(1, 6) / 100,\n",
    "        \"acceptableTasks\": list(np.random.choice(\n",
    "            task_kinds, size=np.random.randint(3, 5), replace=False\n",
    "        )),\n",
    "        \"handleSafeTask\": np.random.choice([0, 1], p=[0.25, 0.75]),\n",
    "    }\n",
    "    devices_data_IOT.append(device_info)\n",
    "\n",
    "IoTdevices = pd.DataFrame(devices_data_IOT)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _MEC_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "source": [
    "devices_data_MEC = []\n",
    "for i in range(num_MEC_devices):\n",
    "    cpu_cores = np.random.choice([16, 32, 64])\n",
    "    device_info = {\n",
    "        \"id\":f\"mec {i}\",\n",
    "        \"number_of_cpu_cores\": cpu_cores,\n",
    "        \"occupied_cores\": [0 for _ in range(cpu_cores)],\n",
    "        \"voltages_frequencies\":[\n",
    "            [\n",
    "                voltages_frequencies_MEC[i]\n",
    "                for i in np.random.choice(4, size=3, replace=False)\n",
    "            ]\n",
    "            for core in range(cpu_cores)\n",
    "        ],\n",
    "        \"capacitance\": [np.random.uniform(1.5, 2) * 1e-9 for _ in range(cpu_cores)],\n",
    "        \"powerIdle\": [np.random.choice([550, 650, 750]) * 1e-3 for _ in range(cpu_cores)],\n",
    "        \"errorRate\": np.random.randint(5, 11) / 100,\n",
    "        \"acceptableTasks\": list(np.random.choice(\n",
    "            task_kinds, size=np.random.randint(3, 5), replace=False\n",
    "        )),\n",
    "        \"handleSafeTask\": np.random.choice([0, 1], p=[0.75, 0.25]),\n",
    "        \"batteryLevel\": 100,\n",
    "        \"ISL\": 0,\n",
    "    }\n",
    "    devices_data_MEC.append(device_info)\n",
    "\n",
    "MECDevices = pd.DataFrame(devices_data_MEC)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _CLOUD_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "device_info = [\n",
    "    {\n",
    "        \"id\": 'cloud',\n",
    "        \"number_of_cpu_cores\": 1,\n",
    "        \"occupied_cores\": [0],\n",
    "        \"voltages_frequencies\": [2.8e9, 3.9e9],\n",
    "        \"capacitance\": (13.85, 24.28),\n",
    "        \"powerIdle\": 0,\n",
    "        \"ISL\": 0,\n",
    "        \"batteryLevel\": 100,\n",
    "        \"errorRate\": 0.1,\n",
    "        \"acceptableTasks\": [1, 2, 3, 4],\n",
    "        \"handleSafeTask\": 0,\n",
    "    }\n",
    "]\n",
    "cloud = pd.DataFrame(device_info)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALL THE DEVICES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "import ast\n",
    "\n",
    "devices = pd.concat([IoTdevices,MECDevices,cloud],ignore_index=True)\n",
    "devices.to_csv(\"devices.csv\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _helper function : generate_random_dag_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "def generate_random_dag(num_nodes):\n",
    "    dag = nx.DiGraph()\n",
    "\n",
    "    nodes = [f\"t{i+1}\" for i in range(num_nodes)]\n",
    "    dag.add_nodes_from(nodes)\n",
    "\n",
    "    available_parents = {node: list(nodes[:i]) for i, node in enumerate(nodes)}\n",
    "\n",
    "    for i in range(2, num_nodes + 1):\n",
    "\n",
    "        num_parents = min(\n",
    "            random.randint(1, min(i, max_num_parents_dag)), len(\n",
    "                available_parents[f\"t{i}\"])\n",
    "        )\n",
    "\n",
    "        # select parents\n",
    "        parent_nodes = random.sample(available_parents[f\"t{i}\"], num_parents)\n",
    "        # add parents\n",
    "        dag.add_edges_from((parent_node, f\"t{i}\")\n",
    "                           for parent_node in parent_nodes)\n",
    "\n",
    "        # update available parents\n",
    "        available_parents[f\"t{i}\"] = list(nodes[:i])\n",
    "\n",
    "    return dag"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Generate task DAGs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "tasks_data = []\n",
    "\n",
    "start_node_number = 1\n",
    "for run in range(num_dag_generations):\n",
    "\n",
    "    num_nodes = random.randint(min_num_nodes_dag, max_num_nodes_dag)\n",
    "\n",
    "    random_dag = generate_random_dag(num_nodes)\n",
    "\n",
    "    mapping = {\n",
    "        f\"t{i}\": f\"t{i + start_node_number - 1}\" for i in range(1, num_nodes + 1)\n",
    "    }\n",
    "\n",
    "    random_dag = nx.relabel_nodes(random_dag, mapping)\n",
    "    for node in random_dag.nodes:\n",
    "        parents = list(random_dag.predecessors(node))\n",
    "        task_info = {\n",
    "            \"id\": node,\n",
    "            \"job\": run,\n",
    "            \"dependency\": parents,\n",
    "            \"mobility\": np.random.randint(1, 10),\n",
    "            \"kind\": np.random.choice(task_kinds),\n",
    "            \"safe\": np.random.choice([0, 1], p=[0.95, 0.05]),\n",
    "            \"computationalLoad\": int(np.random.uniform(1, 11)*1e6),\n",
    "            \"dataEntrySize\":int(np.random.uniform(1, 11)*1e6),\n",
    "            \"returnDataSize\":int(np.random.uniform(1, 11)*1e6),\n",
    "            \"status\": \"READY\",\n",
    "        }\n",
    "        tasks_data.append(task_info)\n",
    "    start_node_number += num_nodes\n",
    "\n",
    "np.random.shuffle(tasks_data)\n",
    "tasks = pd.DataFrame(tasks_data)\n",
    "\n",
    "tasks.to_csv(\"tasks.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : DDT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Initializing The tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "source": [
    "class DDT(nn.Module):\n",
    "    def __init__(self, num_input, num_output, depth, max_depth):\n",
    "        super(DDT, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        if depth != max_depth:\n",
    "            # self.weights = nn.Parameter(torch.zeros(num_input))\n",
    "            self.weights = nn.Parameter(torch.empty(\n",
    "                num_input).normal_(mean=0, std=0.1))\n",
    "            self.bias = nn.Parameter(torch.zeros(1))\n",
    "        if depth == max_depth:\n",
    "            self.prob_dist = nn.Parameter(torch.zeros(num_output))\n",
    "\n",
    "        if depth < max_depth:\n",
    "            self.left = DDT(num_input, num_output, depth + 1, max_depth)\n",
    "            self.right = DDT(num_input, num_output, depth + 1, max_depth)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.depth == self.max_depth:\n",
    "            return self.prob_dist\n",
    "        val = torch.sigmoid(torch.matmul(x, self.weights.t()) + self.bias)\n",
    "        a = np.random.uniform(0, 1)\n",
    "        if a < 0.1:\n",
    "            val = 1 - val\n",
    "        if val >= 0.5:\n",
    "\n",
    "            return val * self.right(x)\n",
    "        else:\n",
    "\n",
    "            return (1 - val) * self.left(x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: RL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "source": [
    "def calc_execution_time(device, task, core, dvfs):\n",
    "    if device['id'] == \"cloud\":\n",
    "        return task[\"computationalLoad\"] / device[\"voltages_frequencies\"][0]\n",
    "    else:\n",
    "        return task[\"computationalLoad\"] / device[\"voltages_frequencies\"][core][dvfs][0]\n",
    "\n",
    "\n",
    "def calc_power_consumption(device, task, core, dvfs):\n",
    "    if device['id'] == \"cloud\":\n",
    "        return 13.85 * calc_execution_time(device, task, core, dvfs)\n",
    "    return (\n",
    "        device[\"capacitance\"][core]\n",
    "        * (device[\"voltages_frequencies\"][core][dvfs][1] ** 2)\n",
    "        * device[\"voltages_frequencies\"][core][dvfs][0]\n",
    "    )\n",
    "def calc_energy(device, task, core, dvfs):\n",
    "    return calc_execution_time(device, task, core, dvfs) * calc_power_consumption(device, task, core, dvfs)\n",
    "\n",
    "\n",
    "def calc_total(device, task, core, dvfs):\n",
    "    timeTransMec = 0\n",
    "    timeTransCC = 0\n",
    "    exeTime = 0\n",
    "    e = 0\n",
    "\n",
    "    transferRate5g =1e9\n",
    "    latency5g=5e-3\n",
    "    transferRateFiber =1e10\n",
    "    latencyFiber=1e-3\n",
    "\n",
    "    timeDownMec = task[\"returnDataSize\"] / transferRate5g\n",
    "    timeDownMec += latency5g\n",
    "    timeUpMec = task[\"dataEntrySize\"] / transferRate5g\n",
    "    timeUpMec += latency5g\n",
    "\n",
    "    alpha = 52e-5\n",
    "    beta = 3.86412\n",
    "    powerMec = alpha * 1e9 / 1e6 + beta\n",
    "\n",
    "    timeDownCC = task[\"returnDataSize\"] / transferRateFiber\n",
    "    timeDownCC += latencyFiber\n",
    "    timeUpCC = task[\"dataEntrySize\"] / transferRateFiber\n",
    "    timeUpCC += latencyFiber\n",
    "\n",
    "    powerCC = 3.65 \n",
    "\n",
    "\n",
    "    if device[\"id\"].startswith(\"mec\"):\n",
    "        timeTransMec =  timeUpMec +  timeDownMec \n",
    "        energyTransMec = powerMec *  timeTransMec\n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime = exeTime + timeTransMec \n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy =  e + energyTransMec\n",
    "\n",
    "    elif device['id'].startswith(\"cloud\"):\n",
    "        timeTransMec =  timeUpMec +  timeDownMec \n",
    "        energyTransMec = powerMec * timeTransMec\n",
    "        \n",
    "        timeTransCC = timeUpCC+timeDownCC\n",
    "        energyTransCC =  powerCC * timeTransCC\n",
    "        \n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime =  exeTime + timeTransMec +timeTransCC\n",
    "\n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy =  + energyTransMec + energyTransCC\n",
    "\n",
    "    elif device['id'].startswith(\"iot\"):\n",
    "        exeTime = calc_execution_time(device, task, core, dvfs)\n",
    "        totalTime = exeTime\n",
    "        e = calc_energy(device, task, core, dvfs)\n",
    "        totalEnergy = e\n",
    "\n",
    "    return totalTime , totalEnergy"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "# devices"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "source": [
    "tasks_copy = tasks.copy()\n",
    "tasks_copy = tasks_copy.drop([\"job\",\"dependency\",\"mobility\",\"status\"],axis=1)\n",
    "taskList = tasks_copy.index.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "source": [
    "devices"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "source": [
    "def checkIfSuitable(state, device):\n",
    "    punishment = 0\n",
    "    safeFail = 0\n",
    "    taskFail = 0\n",
    "    if  state['safe'] and not device[\"handleSafeTask\"]:\n",
    "        punishment += 25\n",
    "        safeFail += 1\n",
    "        \n",
    "    if state['kind'] not in device[\"acceptableTasks\"]:\n",
    "        punishment += 25\n",
    "        taskFail += 1\n",
    "    return (20 if punishment > 0 else 0, taskFail, safeFail)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "source": [
    "def getSetup(t, e, setup, alpha=1, beta=1):\n",
    "    match setup:\n",
    "        case \"00\":\n",
    "            reward = -1 * (e + t)\n",
    "        case \"01\":\n",
    "            reward = -1 * (alpha * e + beta * t)\n",
    "        case \"02\":\n",
    "            reward = -1 / (e + t)\n",
    "        case \"03\":\n",
    "            reward = -1 / (alpha * e + beta * t)\n",
    "        case \"04\":\n",
    "            reward = -np.exp(e) - np.exp(t)\n",
    "        case \"05\":\n",
    "            reward = -np.exp(alpha * e) - np.exp(beta * t)\n",
    "        case \"06\":\n",
    "            reward = -np.exp(t + e)\n",
    "        case \"07\":\n",
    "            reward = -np.exp(alpha * t + beta * e)\n",
    "        case \"08\":\n",
    "            reward = np.exp(-t - e)\n",
    "        case \"09\":\n",
    "            reward = np.exp(-1 * (alpha * t + beta * e))\n",
    "    \n",
    "    return reward"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.totalSafeFail = 0\n",
    "        self.totalTaskFail = 0\n",
    "        self.totalReward = 0\n",
    "        self.feature_size = 5\n",
    "        self.num_actions = len(devices)\n",
    "        self.max_depth = 3\n",
    "        self.agent = DDT(self.feature_size, self.num_actions,\n",
    "                         depth=0, max_depth=self.max_depth)\n",
    "        self.optimizer = optim.Adam(self.agent.parameters(), lr=0.005)\n",
    "\n",
    "    def execute_action(self, state, action):\n",
    "        taskList.pop(0)\n",
    "        device = devices.iloc[action]        \n",
    "\n",
    "        punishment, taskFail, safeFail = checkIfSuitable(state, device)\n",
    "        if safeFail:\n",
    "            self.totalSafeFail += 1\n",
    "        if taskFail:\n",
    "            self.totalTaskFail += 1\n",
    "\n",
    "\n",
    "        if not (punishment):\n",
    "            for coreIndex in range(len(device[\"occupied_cores\"])):\n",
    "                if device[\"occupied_cores\"][coreIndex] == 0:\n",
    "                    total_t, total_e  = calc_total(device, state, coreIndex,np.random.randint(0,3))\n",
    "                    reward = getSetup(total_t, total_e, \"04\")\n",
    "                    # reward = -1 / (total_t + total_e)\n",
    "                    # print(f\"device {device['id']} ////// time {total_t}  ////// energy {total_e} \")\n",
    "                    env.totalReward += reward\n",
    "                    return (tasks_copy.loc[taskList[0]], reward, total_t, total_e)\n",
    "        self.totalFail += 1\n",
    "        return (tasks_copy.loc[taskList[0]], punishment, 0, 0)\n",
    "\n",
    "\n",
    "    def train(self, num_epoch, num_episodes):\n",
    "\n",
    "        total_avg_t = 0\n",
    "        total_avg_e = 0\n",
    "        total_avg_r = 0\n",
    "        total_avg_l = 0\n",
    "\n",
    "        for i in range(num_epoch):\n",
    "            total_loss = 0\n",
    "            env.totalFail = 0\n",
    "            env.totalTaskFail = 0\n",
    "            env.totalSafeFail = 0\n",
    "            env.totalReward = 0\n",
    "            total_loss = 0\n",
    "            total_reward = 0\n",
    "            totalTime = 0\n",
    "            totalEnergy = 0\n",
    "\n",
    "\n",
    "            \n",
    "            for j in range(num_episodes):\n",
    "                state = tasks_copy.loc[taskList[0]]\n",
    "                print(state)\n",
    "                x = torch.tensor(np.array(state.values, dtype=np.float32)).unsqueeze(0)\n",
    "                \n",
    "                output = self.agent(x)\n",
    "                action_probabilities = torch.softmax(output, dim=0)\n",
    "                action_index = torch.multinomial(action_probabilities, 1).item()\n",
    "\n",
    "                next_state, reward, t, e = self.execute_action(state, action_index)\n",
    "                loss = (output[action_index] * reward)\n",
    "\n",
    "                total_reward += reward\n",
    "                total_loss += loss\n",
    "                totalTime += t\n",
    "                totalEnergy += e\n",
    "                \n",
    "                \n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            avg_loss = total_loss/num_episodes\n",
    "            avg_time = totalTime / num_episodes\n",
    "            avg_energy = totalEnergy / num_episodes\n",
    "            \n",
    "            # avg_reward = total_reward / num_episodes\n",
    "            avg_reward = env.totalReward / num_episodes\n",
    "            avg_loss = total_loss/num_episodes\n",
    "\n",
    "\n",
    "            total_avg_t += avg_time\n",
    "            total_avg_e += avg_energy\n",
    "            total_avg_l += avg_loss\n",
    "            total_avg_r += avg_reward\n",
    "            \n",
    "\n",
    "            avg_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                # print(f\"Epoch {i+1} // avg cc time: {avg_cc} // avg mec: {avg_mec} // avg og time: {avg_og} total fail: {env.totalFail} // Average Loss: {avg_loss}// \")\n",
    "                # print(f\"Epoch {i+1} // avg time: {avg_time} // avg added Time: {avg_added_time} // avg og time: {avg_og} total fail: {env.totalFail} // Average Loss: {avg_loss}// \")\n",
    "                print(f\"Epoch {i+1}  // safe/task fail: {env.totalSafeFail}/{env.totalTaskFail} // Average Loss: {avg_loss:.2f} // Total Reward: {env.totalReward:.2f} // Average Reward: {avg_reward:.2f} // Avg time: {avg_time:.2f} // Avg energy: {avg_energy:.2f}\")\n",
    "            \n",
    "            # if i == 10001:\n",
    "                \n",
    "            #     print(f\"safe/task fail: {env.totalSafeFail}/{env.totalTaskFail} // Average Loss: {avg_loss:.2f} // Total Reward: {env.totalReward:.2f} // Average Reward: {avg_reward:.2f} // Avg time: {avg_time:.2f} // Avg energy: {avg_energy:.2f}\")\n",
    "\n",
    "                # env.totalFail = 0\n",
    "                env.totalSafeFail = 0\n",
    "                env.totalTaskFail\n",
    "\n",
    "        avg_avg_t = total_avg_t / num_epoch\n",
    "        avg_avg_l = total_avg_l / num_epoch\n",
    "        avg_avg_r = total_avg_r / num_epoch\n",
    "        avg_avg_e = total_avg_e / num_epoch\n",
    "\n",
    "\n",
    "        print(\"===============================================================================\")\n",
    "        print(f'Overall Average Time across all epochs: {avg_avg_t}')\n",
    "        print(f'Overall Average e across all epochs: {avg_avg_e:.2f}')\n",
    "        print(f'Overall Average l across all epochs: {avg_avg_l:.2f}')\n",
    "        print(f'Overall Average r across all epochs: {avg_avg_r:.2f}')\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# env.totalAddedAvg += avg_cc\n",
    "\n",
    "\n",
    "env = Environment()\n",
    "tree = env.agent\n",
    "env.train(1, 1)\n",
    "\n",
    "print('///////////////////')\n",
    "\n",
    "for name, param in env.agent.named_parameters():\n",
    "    if \"prob_dist\" or \"bias\" not in name:\n",
    "        # print(name,param)\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
